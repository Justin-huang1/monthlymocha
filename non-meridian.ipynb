{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac1510c-f3e3-4018-bfd8-a84e8ca0e34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned channels: ['amazon', 'beehiiv', 'engine', 'google', 'liveintent', 'meta', 'moloco', 'roku', 'snapchat', 'tiktok']\n",
      "Best holdout MSE=5624327.822 | decay=0.315 alpha=0.376 lam=0.1498\n",
      "\n",
      "=== Model summary ===\n",
      "            metric         value\n",
      "RMSE_train_holdout   2371.566533\n",
      "             decay      0.315225\n",
      "             alpha      0.376348\n",
      "            lambda      0.149791\n",
      "subscriptions_mean  12387.702703\n",
      " subscriptions_sum 916690.000000\n",
      "\n",
      "=== Channel ROI (sorted) ===\n",
      "   channel  ROI_$per$  revenue_contrib_total  spend_total\n",
      "liveintent  15.210604           1.213787e+07 7.979872e+05\n",
      "    moloco  13.845291           1.166098e+07 8.422346e+05\n",
      "    engine   3.571356           5.231170e+06 1.464757e+06\n",
      "  snapchat   2.098478           9.112509e+06 4.342437e+06\n",
      "   beehiiv   1.880473           6.171192e+05 3.281723e+05\n",
      "    tiktok   0.401850           7.043170e+05 1.752685e+06\n",
      "    google   0.347429           3.578017e+06 1.029854e+07\n",
      "      roku   0.000000           0.000000e+00 1.000000e-09\n",
      "      meta  -1.155803          -9.710574e+05 8.401581e+05\n",
      "    amazon -32.988387          -5.192457e+05 1.574026e+04\n",
      "\n",
      "Wrote: mmm_summary.csv, channel_roi.csv, channel_contributions.csv, model_fit_timeseries.csv\n",
      "Scenario Budget_90pct: projected subs total = 1,035,008.8 (alloc written to optimization_Budget_90pct_allocation.csv)\n",
      "Scenario Budget_100pct: projected subs total = 1,040,299.6 (alloc written to optimization_Budget_100pct_allocation.csv)\n",
      "Scenario Budget_110pct: projected subs total = 1,045,183.8 (alloc written to optimization_Budget_110pct_allocation.csv)\n",
      "Scenario Budget_120pct: projected subs total = 1,049,718.5 (alloc written to optimization_Budget_120pct_allocation.csv)\n",
      "\n",
      "Wrote: optimization_scenarios_summary.csv and per-scenario allocation CSVs.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Load & basic wrangling\n",
    "# -----------------------------\n",
    "DATA_PATH = Path(\"MMM_Takehome_Dataset.csv\")\n",
    "if not DATA_PATH.exists():\n",
    "    alt = Path(\"MMM Takehome Dataset (1).csv\")\n",
    "    if alt.exists(): DATA_PATH = alt\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df = df.copy()\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Clean NAs\n",
    "for c in df.columns:\n",
    "    if c.endswith(\"_spend\") or c.endswith(\"_impressions\") or c.endswith(\"_impression\"):\n",
    "        df[c] = df[c].fillna(0.0)\n",
    "df[\"subscriptions\"] = df[\"subscriptions\"].clip(lower=0)\n",
    "\n",
    "# Controls: trend + weekly seasonality (Fourier K=3)\n",
    "df[\"t\"] = np.arange(len(df), dtype=float)\n",
    "df[\"weekofyear\"] = df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "for k in range(1, 3+1):\n",
    "    df[f\"sin_woy_{k}\"] = np.sin(2*np.pi*k*df[\"weekofyear\"]/52.0)\n",
    "    df[f\"cos_woy_{k}\"] = np.cos(2*np.pi*k*df[\"weekofyear\"]/52.0)\n",
    "\n",
    "REVENUE_PER_SUB = 100.0\n",
    "df[\"revenue_per_subscription\"] = REVENUE_PER_SUB\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Discover & align channels\n",
    "# (only keep channels with BOTH spend & impressions)\n",
    "# -----------------------------\n",
    "spend_cols = [c for c in df.columns if c.endswith(\"_spend\")]\n",
    "impr_cols  = [c for c in df.columns if c.endswith(\"_impressions\") or c.endswith(\"_impression\")]\n",
    "\n",
    "def _base(col: str) -> str:\n",
    "    return (col.replace(\"_spend\",\"\").replace(\"_impressions\",\"\").replace(\"_impression\",\"\"))\n",
    "\n",
    "def _impr_col_for(ch: str):\n",
    "    if f\"{ch}_impressions\" in df.columns: return f\"{ch}_impressions\"\n",
    "    if f\"{ch}_impression\"  in df.columns: return f\"{ch}_impression\"\n",
    "    return None\n",
    "\n",
    "channels = sorted(set(_base(c) for c in spend_cols + impr_cols))\n",
    "aligned_channels, aligned_spend_cols, aligned_impr_cols = [], [], []\n",
    "for ch in channels:\n",
    "    sc, ic = f\"{ch}_spend\", _impr_col_for(ch)\n",
    "    if (sc in df.columns) and (ic is not None):\n",
    "        aligned_channels.append(ch)\n",
    "        aligned_spend_cols.append(sc)\n",
    "        aligned_impr_cols.append(ic)\n",
    "\n",
    "print(\"Aligned channels:\", aligned_channels)\n",
    "\n",
    "# CPM-like factor to convert $ -> impressions (robust median)\n",
    "impr_per_dollar = {}\n",
    "for ch, sc, ic in zip(aligned_channels, aligned_spend_cols, aligned_impr_cols):\n",
    "    denom = df[sc].replace(0, np.nan)\n",
    "    ratio = (df[ic] / denom).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    impr_per_dollar[ch] = float(np.median(ratio)) if len(ratio) else 0.0\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Feature engineering\n",
    "#    - geometric adstock\n",
    "#    - Hill saturation (concave)\n",
    "# -----------------------------\n",
    "def adstock_geometric(x: np.ndarray, decay: float) -> np.ndarray:\n",
    "    \"\"\"x: (T,), decay in (0,1).\"\"\"\n",
    "    out = np.zeros_like(x, dtype=float)\n",
    "    for t in range(len(x)):\n",
    "        out[t] = x[t] + (out[t-1] * decay if t > 0 else 0.0)\n",
    "    return out\n",
    "\n",
    "def hill_saturation(x: np.ndarray, alpha: float, ec50: float) -> np.ndarray:\n",
    "    \"\"\"alpha>0 (shape), ec50>0 (half-saturation).\"\"\"\n",
    "    x_pos = np.clip(x, 0, None)\n",
    "    return np.power(x_pos, alpha) / (np.power(x_pos, alpha) + np.power(ec50, alpha))\n",
    "\n",
    "# Build control matrix\n",
    "control_cols = [\"t\",\"sin_woy_1\",\"cos_woy_1\",\"sin_woy_2\",\"cos_woy_2\",\"sin_woy_3\",\"cos_woy_3\"]\n",
    "X_controls = df[control_cols].to_numpy()\n",
    "y = df[\"subscriptions\"].to_numpy()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Train/holdout split\n",
    "# -----------------------------\n",
    "H = min(12, max(4, len(df)//10))  # last ~12 weeks for holdout (at least 4)\n",
    "train_idx = np.arange(0, len(df)-H)\n",
    "test_idx  = np.arange(len(df)-H, len(df))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Hyperparameter search (tiny, fast)\n",
    "#    decay (0.2..0.9), alpha (0.3..2.0), ridge lambda (1e-3..1e2)\n",
    "#    ec50 tuned per-channel to a data percentile of adstocked exposure\n",
    "# -----------------------------\n",
    "rng = np.random.default_rng(42)\n",
    "n_search = 60\n",
    "\n",
    "def fit_ridge(X, y, lam):\n",
    "    # closed-form ridge (add small jitter for safety)\n",
    "    XT_X = X.T @ X\n",
    "    p = XT_X.shape[0]\n",
    "    beta = np.linalg.solve(XT_X + lam*np.eye(p), X.T @ y)\n",
    "    return beta\n",
    "\n",
    "def mse(a, b): \n",
    "    d = a - b\n",
    "    return float(np.mean(d*d))\n",
    "\n",
    "best = {\"score\": np.inf}\n",
    "\n",
    "for _ in range(n_search):\n",
    "    decay  = float(rng.uniform(0.2, 0.9))\n",
    "    alpha  = float(rng.uniform(0.3, 2.0))\n",
    "    lam    = 10.0 ** float(rng.uniform(-3, 2))\n",
    "\n",
    "    # Build media features with this (decay, alpha)\n",
    "    X_media = []\n",
    "    for ch, ic in zip(aligned_channels, aligned_impr_cols):\n",
    "        # adstock on impressions\n",
    "        ad = adstock_geometric(df[ic].to_numpy().astype(float), decay)\n",
    "        # ec50 = percentile of adstocked exposure (robust to scale)\n",
    "        ec50 = np.percentile(ad[train_idx], 70.0) + 1e-6\n",
    "        sat = hill_saturation(ad, alpha, ec50)\n",
    "        X_media.append(sat)\n",
    "    X_media = np.vstack(X_media).T if X_media else np.zeros((len(df), 0))\n",
    "\n",
    "    # Design matrices (add intercept)\n",
    "    X_full   = np.hstack([np.ones((len(df),1)), X_controls, X_media])\n",
    "    X_tr, y_tr = X_full[train_idx], y[train_idx]\n",
    "    X_te, y_te = X_full[test_idx],  y[test_idx]\n",
    "\n",
    "    beta = fit_ridge(X_tr, y_tr, lam)\n",
    "    y_hat_te = X_te @ beta\n",
    "    score = mse(y_te, y_hat_te)\n",
    "\n",
    "    if score < best[\"score\"]:\n",
    "        best = dict(score=score, decay=decay, alpha=alpha, lam=lam, beta=beta, ec50s=[])\n",
    "\n",
    "        # keep per-channel ec50 used (for later reporting)\n",
    "        ec50s = []\n",
    "        for ch, ic in zip(aligned_channels, aligned_impr_cols):\n",
    "            ad = adstock_geometric(df[ic].to_numpy().astype(float), decay)\n",
    "            ec50s.append(np.percentile(ad[train_idx], 70.0) + 1e-6)\n",
    "        best[\"ec50s\"] = ec50s\n",
    "\n",
    "print(f\"Best holdout MSE={best['score']:.3f} | decay={best['decay']:.3f} alpha={best['alpha']:.3f} lam={best['lam']:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Refit on ALL data with best hyperparams\n",
    "# -----------------------------\n",
    "decay_opt = best[\"decay\"]; alpha_opt = best[\"alpha\"]; lam_opt = best[\"lam\"]; ec50s_opt = best[\"ec50s\"]\n",
    "\n",
    "X_media_opt = []\n",
    "for (ch, ic, ec50) in zip(aligned_channels, aligned_impr_cols, ec50s_opt):\n",
    "    ad = adstock_geometric(df[ic].to_numpy().astype(float), decay_opt)\n",
    "    sat = hill_saturation(ad, alpha_opt, ec50)\n",
    "    X_media_opt.append(sat)\n",
    "X_media_opt = np.vstack(X_media_opt).T if X_media_opt else np.zeros((len(df), 0))\n",
    "\n",
    "X_full_opt = np.hstack([np.ones((len(df),1)), X_controls, X_media_opt])\n",
    "beta_opt = np.linalg.solve(X_full_opt.T @ X_full_opt + lam_opt*np.eye(X_full_opt.shape[1]), X_full_opt.T @ y)\n",
    "y_hat = X_full_opt @ beta_opt\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Contributions & ROI\n",
    "# -----------------------------\n",
    "# Coefficient mapping\n",
    "p_intercept = 1\n",
    "p_controls  = X_controls.shape[1]\n",
    "p_media     = X_media_opt.shape[1]\n",
    "coefs_intercept = beta_opt[0]\n",
    "coefs_controls  = beta_opt[1:1+p_controls]\n",
    "coefs_media     = beta_opt[1+p_controls:1+p_controls+p_media]\n",
    "\n",
    "# Per-channel contributions (sum over time of media_feature * beta)\n",
    "contribs = {}\n",
    "for j, ch in enumerate(aligned_channels):\n",
    "    channel_feature = X_media_opt[:, j]\n",
    "    contribs[ch] = float(np.sum(channel_feature * coefs_media[j]))\n",
    "\n",
    "# Turn subs->revenue and compute ROI\n",
    "roi_rows = []\n",
    "for j, ch in enumerate(aligned_channels):\n",
    "    subs_from_channel = contribs[ch]\n",
    "    revenue = subs_from_channel * REVENUE_PER_SUB\n",
    "    spend   = float(df[f\"{ch}_spend\"].sum()) + 1e-9\n",
    "    roi     = revenue / spend   # $/$\n",
    "    mroi    = coefs_media[j] * REVENUE_PER_SUB / (np.mean(df[f\"{ch}_spend\"])+1e-9)  # crude local\n",
    "    roi_rows.append({\n",
    "        \"channel\": ch,\n",
    "        \"subs_contrib_total\": subs_from_channel,\n",
    "        \"revenue_contrib_total\": revenue,\n",
    "        \"spend_total\": spend,\n",
    "        \"ROI_$per$\": roi,\n",
    "        \"local_mROI_$per$\": mroi\n",
    "    })\n",
    "roi_df = pd.DataFrame(roi_rows).sort_values(\"ROI_$per$\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Report tables\n",
    "# -----------------------------\n",
    "summary = pd.DataFrame({\n",
    "    \"metric\": [\"RMSE_train_holdout\", \"decay\", \"alpha\", \"lambda\", \"subscriptions_mean\", \"subscriptions_sum\"],\n",
    "    \"value\":  [np.sqrt(best[\"score\"]), decay_opt, alpha_opt, lam_opt, float(np.mean(y)), float(np.sum(y))]\n",
    "})\n",
    "\n",
    "# contributions table\n",
    "contrib_df = pd.DataFrame({\n",
    "    \"channel\": aligned_channels,\n",
    "    \"coefficient\": coefs_media,\n",
    "    \"total_contribution_subs\": [contribs[ch] for ch in aligned_channels],\n",
    "    \"total_spend\": [float(df[f\"{ch}_spend\"].sum()) for ch in aligned_channels]\n",
    "}).sort_values(\"total_contribution_subs\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display compact results\n",
    "print(\"\\n=== Model summary ===\")\n",
    "print(summary.to_string(index=False))\n",
    "print(\"\\n=== Channel ROI (sorted) ===\")\n",
    "print(roi_df[[\"channel\",\"ROI_$per$\",\"revenue_contrib_total\",\"spend_total\"]].to_string(index=False))\n",
    "\n",
    "# Save artifacts\n",
    "summary.to_csv(\"mmm_summary.csv\", index=False)\n",
    "roi_df.to_csv(\"channel_roi.csv\", index=False)\n",
    "contrib_df.to_csv(\"channel_contributions.csv\", index=False)\n",
    "pd.DataFrame({\"date\": df[\"date\"], \"subs\": y, \"subs_hat\": y_hat}).to_csv(\"model_fit_timeseries.csv\", index=False)\n",
    "\n",
    "print(\"\\nWrote: mmm_summary.csv, channel_roi.csv, channel_contributions.csv, model_fit_timeseries.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Simple budget optimization\n",
    "#    Greedy allocation by marginal ROI using the fitted response.\n",
    "#    We assume weekly steady-state (coarse) and use current CPM to map $->impr.\n",
    "# -----------------------------\n",
    "def project_subs_given_spend(multiplier_by_channel: dict):\n",
    "    \"\"\"Project total subs if each channel spend is scaled by a multiplier.\"\"\"\n",
    "    proj_features = []\n",
    "    for j, ch in enumerate(aligned_channels):\n",
    "        sc, ic = f\"{ch}_spend\", aligned_impr_cols[j]\n",
    "        m = multiplier_by_channel.get(ch, 1.0)\n",
    "        # scale spend weekly, map to impressions via median factor\n",
    "        scale = m\n",
    "        impr_scale = impr_per_dollar[ch] if impr_per_dollar[ch] > 0 else 0.0\n",
    "        # Build scaled impressions series (proportional to spend scaling)\n",
    "        base_spend = df[sc].to_numpy()\n",
    "        base_impr  = df[ic].to_numpy()\n",
    "        # favor using actual impressions scaling from spend ratio when spend>0\n",
    "        spend_ratio = (base_spend * scale) / (base_spend + 1e-9)\n",
    "        impr_scaled = base_impr * spend_ratio\n",
    "        # adstock + saturation with fitted params\n",
    "        ad = adstock_geometric(impr_scaled, decay_opt)\n",
    "        sat = hill_saturation(ad, alpha_opt, ec50s_opt[j])\n",
    "        proj_features.append(sat)\n",
    "    proj_features = np.vstack(proj_features).T if proj_features else np.zeros((len(df),0))\n",
    "    X_proj = np.hstack([np.ones((len(df),1)), X_controls, proj_features])\n",
    "    y_proj = X_proj @ beta_opt\n",
    "    return float(np.sum(y_proj)), y_proj\n",
    "\n",
    "# greedy allocator\n",
    "def optimize_budget(total_multiplier=1.0, steps=200):\n",
    "    current_spend_total = float(sum(df[f\"{ch}_spend\"].sum() for ch in aligned_channels))\n",
    "    target_spend = current_spend_total * total_multiplier\n",
    "    step_size = max(target_spend / steps, 1e-6)  # $ quantum\n",
    "    # start from current multipliers = 1.0\n",
    "    multipliers = {ch: 1.0 for ch in aligned_channels}\n",
    "    # compute marginal gains by adding step_size to one channel at a time\n",
    "    for _ in range(steps):\n",
    "        best_ch, best_gain = None, -1e18\n",
    "        base_total, _ = project_subs_given_spend(multipliers)\n",
    "        for ch in aligned_channels:\n",
    "            # add tiny increment proportionally to that channel's share\n",
    "            inc = step_size / (df[f\"{ch}_spend\"].sum() + 1e-9)\n",
    "            trial = multipliers.copy(); trial[ch] = multipliers[ch] + inc\n",
    "            trial_total, _ = project_subs_given_spend(trial)\n",
    "            gain = trial_total - base_total\n",
    "            if gain > best_gain:\n",
    "                best_gain, best_ch = gain, ch\n",
    "        # apply increment to the best channel\n",
    "        multipliers[best_ch] = multipliers[best_ch] + (step_size / (df[f\"{best_ch}_spend\"].sum() + 1e-9))\n",
    "    return multipliers\n",
    "\n",
    "scenarios = {\n",
    "    \"Budget_90pct\": 0.90,\n",
    "    \"Budget_100pct\": 1.00,\n",
    "    \"Budget_110pct\": 1.10,\n",
    "    \"Budget_120pct\": 1.20,\n",
    "}\n",
    "\n",
    "opt_rows = []\n",
    "for name, mult in scenarios.items():\n",
    "    mults = optimize_budget(total_multiplier=mult, steps=120)\n",
    "    total_subs, yp = project_subs_given_spend(mults)\n",
    "    row = {\"scenario\": name, \"budget_multiplier\": mult, \"projected_subscriptions_total\": total_subs}\n",
    "    # derive channel allocation %\n",
    "    alloc = []\n",
    "    for ch in aligned_channels:\n",
    "        alloc.append({\n",
    "            \"scenario\": name,\n",
    "            \"channel\": ch,\n",
    "            \"multiplier\": mults[ch],\n",
    "            \"spend_total_new\": float(df[f\"{ch}_spend\"].sum()) * mults[ch]\n",
    "        })\n",
    "    alloc_df = pd.DataFrame(alloc)\n",
    "    alloc_df[\"allocation_share\"] = alloc_df[\"spend_total_new\"] / alloc_df[\"spend_total_new\"].sum()\n",
    "    alloc_df.to_csv(f\"optimization_{name}_allocation.csv\", index=False)\n",
    "    print(f\"Scenario {name}: projected subs total = {total_subs:,.1f} (alloc written to optimization_{name}_allocation.csv)\")\n",
    "    opt_rows.append(row)\n",
    "\n",
    "opt_df = pd.DataFrame(opt_rows).sort_values(\"budget_multiplier\")\n",
    "opt_df.to_csv(\"optimization_scenarios_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nWrote: optimization_scenarios_summary.csv and per-scenario allocation CSVs.\")\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeeb43fd-9330-4e97-9e7b-7629f83e485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12 | OS darwin | Arch arm64\n",
      "$ /opt/anaconda3/bin/python -m pip install -U google-meridian\n",
      "Requirement already satisfied: google-meridian in /opt/anaconda3/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: arviz in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (0.20.0)\n",
      "Requirement already satisfied: altair>=5 in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (5.0.1)\n",
      "Requirement already satisfied: immutabledict in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (4.2.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (1.4.2)\n",
      "Requirement already satisfied: natsort<8,>=7.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (7.1.1)\n",
      "Requirement already satisfied: numpy<3,>=2.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (2.0.2)\n",
      "Requirement already satisfied: pandas<3,>=2.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (2.3.3)\n",
      "Requirement already satisfied: patsy<0.5.4,>=0.5.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (0.5.3)\n",
      "Requirement already satisfied: scipy<2,>=1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (0.14.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (2.18.1)\n",
      "Requirement already satisfied: tensorflow-probability<0.26,>=0.25 in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (0.25.0)\n",
      "Requirement already satisfied: tf-keras<2.19,>=2.18 in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (2.18.0)\n",
      "Requirement already satisfied: xarray in /opt/anaconda3/lib/python3.12/site-packages (from google-meridian) (2023.6.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from altair>=5->google-meridian) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from altair>=5->google-meridian) (4.23.0)\n",
      "Requirement already satisfied: toolz in /opt/anaconda3/lib/python3.12/site-packages (from altair>=5->google-meridian) (0.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3,>=2.2.2->google-meridian) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3,>=2.2.2->google-meridian) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3,>=2.2.2->google-meridian) (2023.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from patsy<0.5.4,>=0.5.3->google-meridian) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.12/site-packages (from statsmodels>=0.12.2->google-meridian) (24.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (80.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (1.75.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->google-meridian) (0.5.3)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-probability<0.26,>=0.25->google-meridian) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-probability<0.26,>=0.25->google-meridian) (3.0.0)\n",
      "Requirement already satisfied: dm-tree in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-probability<0.26,>=0.25->google-meridian) (0.1.9)\n",
      "Requirement already satisfied: matplotlib>=3.5 in /opt/anaconda3/lib/python3.12/site-packages (from arviz->google-meridian) (3.9.2)\n",
      "Requirement already satisfied: h5netcdf>=1.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from arviz->google-meridian) (1.5.0)\n",
      "Requirement already satisfied: xarray-einstats>=0.3 in /opt/anaconda3/lib/python3.12/site-packages (from arviz->google-meridian) (0.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->google-meridian) (0.45.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair>=5->google-meridian) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair>=5->google-meridian) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair>=5->google-meridian) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair>=5->google-meridian) (0.10.6)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->google-meridian) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->google-meridian) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->google-meridian) (0.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.5->arviz->google-meridian) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.5->arviz->google-meridian) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.5->arviz->google-meridian) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.5->arviz->google-meridian) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.5->arviz->google-meridian) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.5->arviz->google-meridian) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->google-meridian) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->google-meridian) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->google-meridian) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->google-meridian) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->google-meridian) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->google-meridian) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->google-meridian) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->altair>=5->google-meridian) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->google-meridian) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->google-meridian) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->google-meridian) (0.1.0)\n",
      "TFP already present.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_frame_input_data_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrameInputDataBuilder\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Meridian, save_mmm\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelSpec\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/meridian/__init__.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2025 The Meridian Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Meridian API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m analysis\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/meridian/analysis/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2025 The Meridian Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Meridian analysis API for trained models.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m analyzer\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m formatter\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/meridian/analysis/analyzer.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Optional\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeridian\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adstock_hill\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/meridian/backend/__init__.py:577\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAX does not support a global, stateful random seed. `set_random_seed`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not implemented. Instead, you must pass an explicit `seed`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m integer directly to the sampling methods (e.g., `sample_prior`),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m which will be used to create a JAX PRNGKey internally.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m     )\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _BACKEND \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39mBackend\u001b[38;5;241m.\u001b[39mTENSORFLOW:\n\u001b[0;32m--> 577\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf_backend\u001b[39;00m\n\u001b[1;32m    578\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfp\u001b[39;00m\n\u001b[1;32m    580\u001b[0m   _ops \u001b[38;5;241m=\u001b[39m tf_backend\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_util\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/feature_column/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.feature_column namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenseColumn \u001b[38;5;66;03m# line: 1777\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeatureTransformationCache \u001b[38;5;66;03m# line: 1962\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequenceDenseColumn \u001b[38;5;66;03m# line: 1941\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/feature_column/feature_column_v2.py:38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m readers\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column \u001b[38;5;28;01mas\u001b[39;00m fc_old\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column_v2_types \u001b[38;5;28;01mas\u001b[39;00m fc_types\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/feature_column/feature_column.py:41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m sparse_tensor_lib\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops_stack\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/layers/base.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_tf_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[1;32m     18\u001b[0m InputSpec \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mInputSpec\n\u001b[1;32m     20\u001b[0m keras_style_scope \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mkeras_style_scope\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/keras/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/keras/models.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_module\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sequential\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/keras/engine/functional.py:33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m network_serialization\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/keras/engine/training.py:54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_scale_optimizer \u001b[38;5;28;01mas\u001b[39;00m lso\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m policy\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hdf5_format\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_utils\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/keras/saving/hdf5_format.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m     38\u001b[0m   HDF5_OBJECT_HEADER_LIMIT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64512\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/h5py/__init__.py:45\u001b[0m\n\u001b[1;32m     36\u001b[0m     _warn((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5py is running against HDF5 \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m when it was built against \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis may cause problems\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_version_tuple),\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_built_version_tuple)\n\u001b[1;32m     40\u001b[0m     ))\n\u001b[1;32m     43\u001b[0m _errors\u001b[38;5;241m.\u001b[39msilence_errors()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_converters \u001b[38;5;28;01mas\u001b[39;00m _register_converters, \\\n\u001b[1;32m     46\u001b[0m                    unregister_converters \u001b[38;5;28;01mas\u001b[39;00m _unregister_converters\n\u001b[1;32m     47\u001b[0m _register_converters()\n\u001b[1;32m     48\u001b[0m atexit\u001b[38;5;241m.\u001b[39mregister(_unregister_converters)\n",
      "File \u001b[0;32mh5py/_conv.pyx:1\u001b[0m, in \u001b[0;36minit h5py._conv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5r.pyx:1\u001b[0m, in \u001b[0;36minit h5py.h5r\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5p.pyx:1\u001b[0m, in \u001b[0;36minit h5py.h5p\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# ===== Meridian MMM — one-cell, end-to-end =====\n",
    "# This cell:\n",
    "# - Ensures google-meridian and a compatible TF/TFP are available in THIS kernel\n",
    "# - Loads \"MMM_Takehome_Dataset.csv\"\n",
    "# - Builds a single-geo Meridian InputData\n",
    "# - Fits a Bayesian MMM (NUTS/TFP)\n",
    "# - Exports summary + budget optimization + saved model\n",
    "\n",
    "import sys, os, platform, subprocess, site\n",
    "from pathlib import Path\n",
    "\n",
    "def _pip(*args):\n",
    "    cmd = [sys.executable, \"-m\", \"pip\"] + list(args)\n",
    "    print(\"$\", \" \".join(cmd))\n",
    "    out = subprocess.run(cmd, text=True)\n",
    "    if out.returncode != 0:\n",
    "        raise RuntimeError(f\"pip failed: {' '.join(args)}\")\n",
    "\n",
    "# --- 0) Minimal dependency bootstrap (only if needed) ---\n",
    "# We try a small matrix known to work with Meridian 1.2.x\n",
    "# Strategy: pin NumPy<2, then try TFP/TF (2.16/0.24; 2.17/0.25), pick the first that works.\n",
    "\n",
    "def _ensure_stack():\n",
    "    pyver = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n",
    "    osys = platform.system().lower()\n",
    "    arch = platform.machine().lower()\n",
    "    print(f\"Python {pyver} | OS {osys} | Arch {arch}\")\n",
    "\n",
    "    try:\n",
    "        import numpy as _np  # noqa: F401\n",
    "    except Exception:\n",
    "        _pip(\"install\", \"-U\", \"numpy>=1.26,<2\")\n",
    "\n",
    "    # Meridian\n",
    "    try:\n",
    "        import meridian  # noqa: F401\n",
    "    except Exception:\n",
    "        _pip(\"install\", \"-U\", \"google-meridian\")\n",
    "\n",
    "    # If TF/TFP already present, try to import TFP quickly.\n",
    "    def _try_import_tfp():\n",
    "        try:\n",
    "            import tensorflow_probability as tfp  # noqa: F401\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    if _try_import_tfp():\n",
    "        print(\"TFP already present.\")\n",
    "        return\n",
    "\n",
    "    # Choose TF package name by platform\n",
    "    # Linux/Windows: tensorflow-cpu. macOS (Apple Silicon): tensorflow-macos.\n",
    "    tf_pkg = \"tensorflow-cpu\"\n",
    "    if osys == \"darwin\":\n",
    "        tf_pkg = \"tensorflow-macos\"\n",
    "\n",
    "    # Try two combos from newest to older:\n",
    "    combos = [\n",
    "        (\"tensorflow-probability==0.25.0\", f\"{tf_pkg}==2.17.0\"),\n",
    "        (\"tensorflow-probability==0.24.0\", f\"{tf_pkg}==2.16.1\"),\n",
    "    ]\n",
    "\n",
    "    # Some wheels may not exist for Python 3.12 on macOS ARM; catch and fall back to guidance.\n",
    "    for tfp_pin, tf_pin in combos:\n",
    "        try:\n",
    "            _pip(\"install\", \"-U\", \"numpy>=1.26,<2\", tfp_pin, tf_pin)\n",
    "            import tensorflow_probability as tfp  # noqa: F401\n",
    "            print(f\"Using {tfp_pin} with {tf_pin}\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"Combo {tfp_pin} / {tf_pin} failed: {e}\")\n",
    "\n",
    "    # If we got here, current kernel cannot get a compatible TF/TFP wheel.\n",
    "    raise SystemExit(\n",
    "        \"This Python/OS combo cannot install a compatible TensorFlow/TFP for Meridian in-place. \"\n",
    "        \"Create a fresh conda env with Python 3.10 or 3.11, then: \"\n",
    "        \"conda create -n meridian-mmm python=3.10 -y && conda activate meridian-mmm && \"\n",
    "        \"pip install -U google-meridian tensorflow-cpu==2.16.1 tensorflow-probability==0.24.0\"\n",
    "    )\n",
    "\n",
    "_ensure_stack()\n",
    "\n",
    "# --- 1) Imports (now that stack exists) ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from meridian.data.data_frame_input_data_builder import DataFrameInputDataBuilder\n",
    "from meridian.model.model import Meridian, save_mmm\n",
    "from meridian.model.spec import ModelSpec\n",
    "from meridian.model import prior_distribution\n",
    "from meridian import constants\n",
    "from meridian.analysis.summarizer import Summarizer\n",
    "from meridian.analysis.visualizer import ModelDiagnostics, ModelFit\n",
    "from meridian.analysis.optimizer import BudgetOptimizer, FixedBudgetScenario\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# --- 2) Load data ---\n",
    "DATA_PATH = Path(\"MMM_Takehome_Dataset.csv\")\n",
    "if not DATA_PATH.exists():\n",
    "    alt = Path(\"MMM Takehome Dataset (1).csv\")\n",
    "    if alt.exists():\n",
    "        DATA_PATH = alt\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\"Place MMM_Takehome_Dataset.csv next to this notebook.\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# --- 3) Clean & controls ---\n",
    "for c in df.columns:\n",
    "    if c.endswith(\"_spend\") or c.endswith(\"_impressions\") or c.endswith(\"_impression\"):\n",
    "        df[c] = df[c].fillna(0.0)\n",
    "df[\"subscriptions\"] = df[\"subscriptions\"].clip(lower=0)\n",
    "\n",
    "# Trend + weekly Fourier seasonality (K=3)\n",
    "df[\"t\"] = np.arange(len(df), dtype=float)\n",
    "df[\"weekofyear\"] = df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "for k in range(1, 4):\n",
    "    df[f\"sin_woy_{k}\"] = np.sin(2*np.pi*k*df[\"weekofyear\"]/52.0)\n",
    "    df[f\"cos_woy_{k}\"] = np.cos(2*np.pi*k*df[\"weekofyear\"]/52.0)\n",
    "\n",
    "# Revenue per KPI for ROI interpretation\n",
    "df[\"revenue_per_subscription\"] = 100.0\n",
    "\n",
    "# --- 4) Discover channels & ALIGN (require both spend + impressions) ---\n",
    "spend_cols = [c for c in df.columns if c.endswith(\"_spend\")]\n",
    "impr_cols  = [c for c in df.columns if c.endswith(\"_impressions\") or c.endswith(\"_impression\")]\n",
    "\n",
    "def _base(col: str) -> str:\n",
    "    return col.replace(\"_spend\",\"\").replace(\"_impressions\",\"\").replace(\"_impression\",\"\")\n",
    "\n",
    "def _impr_col_for(ch: str):\n",
    "    if f\"{ch}_impressions\" in df.columns: return f\"{ch}_impressions\"\n",
    "    if f\"{ch}_impression\"  in df.columns: return f\"{ch}_impression\"\n",
    "    return None\n",
    "\n",
    "channels = sorted(set(_base(c) for c in spend_cols + impr_cols))\n",
    "media_channels, media_spend_cols, media_cols = [], [], []\n",
    "for ch in channels:\n",
    "    sc, ic = f\"{ch}_spend\", _impr_col_for(ch)\n",
    "    if (sc in df.columns) and (ic is not None):\n",
    "        media_channels.append(ch); media_spend_cols.append(sc); media_cols.append(ic)\n",
    "\n",
    "control_cols = [\"t\",\"sin_woy_1\",\"cos_woy_1\",\"sin_woy_2\",\"cos_woy_2\",\"sin_woy_3\",\"cos_woy_3\"]\n",
    "print(\"Aligned channels:\", media_channels)\n",
    "\n",
    "# --- 5) Build InputData (single-geo national model) ---\n",
    "df[\"geo\"] = \"national\"\n",
    "builder = DataFrameInputDataBuilder(\n",
    "    kpi_type=\"non_revenue\",\n",
    "    default_kpi_column=\"subscriptions\",\n",
    "    default_revenue_per_kpi_column=\"revenue_per_subscription\",\n",
    "    default_time_column=\"date\",\n",
    "    default_geo_column=\"geo\",\n",
    ")\n",
    "builder = builder.with_kpi(df)\n",
    "builder = builder.with_revenue_per_kpi(df)\n",
    "builder = builder.with_controls(df, control_cols=control_cols)\n",
    "builder = builder.with_media(\n",
    "    df,\n",
    "    media_cols=media_cols,\n",
    "    media_spend_cols=media_spend_cols,\n",
    "    media_channels=media_channels,\n",
    ")\n",
    "data = builder.build()\n",
    "print(\"✔ Built Meridian InputData\")\n",
    "\n",
    "# --- 6) Model spec (weakly-informative ROI prior) ---\n",
    "prior = prior_distribution.PriorDistribution(\n",
    "    roi_m=tfp.distributions.LogNormal(0.2, 0.9, name=constants.ROI_M)\n",
    ")\n",
    "model_spec = ModelSpec(prior=prior)\n",
    "\n",
    "# --- 7) Fit Bayesian MMM ---\n",
    "mmm = Meridian(input_data=data, model_spec=model_spec)\n",
    "mmm.sample_prior(n_draws=200, seed=42)\n",
    "mmm.sample_posterior(n_chains=4, n_adapt=1000, n_burnin=300, n_keep=800, seed=42)\n",
    "print(\"✔ Sampling complete\")\n",
    "\n",
    "# --- 8) Diagnostics & fit plots ---\n",
    "ModelDiagnostics(mmm).plot_rhat_boxplot()\n",
    "ModelFit(mmm).plot_model_fit()\n",
    "\n",
    "# --- 9) Two-page summary ---\n",
    "sumr = Summarizer(mmm)\n",
    "start_date = str(df[\"date\"].min().date())\n",
    "end_date   = str(df[\"date\"].max().date())\n",
    "sumr.output_model_results_summary(\"summary_output.html\", \".\", start_date, end_date)\n",
    "print(\"✔ Wrote summary_output.html\")\n",
    "\n",
    "# --- 10) Budget optimization (fixed total budgets) ---\n",
    "opt = BudgetOptimizer(mmm)\n",
    "total_hist_budget = float(opt.get_current_media_spend().sum())\n",
    "scenarios = [\n",
    "    FixedBudgetScenario(total_budget=total_hist_budget * 0.90),\n",
    "    FixedBudgetScenario(total_budget=total_hist_budget * 1.00),\n",
    "    FixedBudgetScenario(total_budget=total_hist_budget * 1.10),\n",
    "    FixedBudgetScenario(total_budget=total_hist_budget * 1.20),\n",
    "]\n",
    "opt_results = opt.optimize(scenarios=scenarios)\n",
    "sumr.output_optimization_results_summary(\n",
    "    \"optimization_output.html\", \".\", start_date, end_date, optimization_results=opt_results\n",
    ")\n",
    "print(\"✔ Wrote optimization_output.html\")\n",
    "\n",
    "# --- 11) Save model ---\n",
    "save_mmm(mmm, \"saved_mmm.pkl\")\n",
    "print(\"✔ Saved model to saved_mmm.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c05e1a-7a8a-4b70-a023-765ff2b15ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
